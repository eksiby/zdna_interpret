{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oPV27ndiIA2x"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/mitiau/DNABERT-Z/blob/main/ZDNA-prediction.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f59Ujuujn___"
   },
   "source": [
    "# Install dependecies and define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "apiUcTpNTnlU",
    "outputId": "f73b267a-d6e2-4c4c-fedd-57e647f05bba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!pip install transformers\\n!pip install biopython\\n!pip install transformers_interpret\\n!pip install numpy==1.25.0\\n!pip install shap\\n!python --version\\n!pip list'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''!pip install transformers\n",
    "!pip install biopython\n",
    "!pip install transformers_interpret\n",
    "!pip install numpy==1.25.0\n",
    "!pip install shap\n",
    "!python --version\n",
    "!pip list'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Bsyfz4BrSxMN"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import transformers\n",
    "from transformers import BertTokenizer, BertForTokenClassification\n",
    "import numpy as np\n",
    "from Bio import SeqIO\n",
    "from io import StringIO, BytesIO\n",
    "#from google.colab import drive, files\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import scipy\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Yk75f6nPIA21"
   },
   "outputs": [],
   "source": [
    "def seq2kmer(seq, k):\n",
    "    if len(seq) < k:\n",
    "        return seq\n",
    "        \n",
    "    kmer = [seq[x:x+k] for x in range(len(seq)+1-k)]\n",
    "    return kmer\n",
    "\n",
    "def split_seq(seq, length = 512, pad = 16):\n",
    "    res = []\n",
    "    for st in range(0, len(seq), length - pad):\n",
    "        end = min(st+512, len(seq))\n",
    "        res.append(seq[st:end])\n",
    "    return res\n",
    "\n",
    "def stitch_np_seq(np_seqs, pad = 16):\n",
    "    res = np.array([])\n",
    "    for seq in np_seqs:\n",
    "        res = res[:-pad]\n",
    "        res = np.concatenate([res,seq])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zuPSfXpxIA21",
    "outputId": "537f94ab-adc5-48af-bc62-a7153cdb040e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!git clone https://github.com/Nazar1997/Sparse_vector.git\\n!git clone https://github.com/vladislareon/z_dna'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''!git clone https://github.com/Nazar1997/Sparse_vector.git\n",
    "!git clone https://github.com/vladislareon/z_dna'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rzQ355CaIA21"
   },
   "source": [
    "# Select model and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "eiUGhsXCIA22"
   },
   "outputs": [],
   "source": [
    "model = 'HG kouzine' #@param [\"HG chipseq\", \"HG kouzine\", \"MM chipseq\", \"MM kouzine\"]\n",
    "model_confidence_threshold = 0.5 #@param {type:\"number\"}\n",
    "minimum_sequence_length = 10 #@param {type:\"integer\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "zciuIzzYIA22"
   },
   "outputs": [],
   "source": [
    "\n",
    "if model == 'HG chipseq':\n",
    "    model_id = '1VAsp8I904y_J0PUhAQqpSlCn1IqfG0FB'\n",
    "elif model == 'HG kouzine':\n",
    "    model_id = '1dAeAt5Gu2cadwDhbc7OnenUgDLHlUvkx'\n",
    "elif model == 'MM curax':\n",
    "    model_id = '1W6GEgHNoitlB-xXJbLJ_jDW4BF35W1Sd'\n",
    "elif model == 'MM kouzine':\n",
    "    model_id = '1dXpQFmheClKXIEoqcZ7kgCwx6hzVCv3H'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2NVXS1MDIA22",
    "outputId": "0b2b70ff-37a9-4774-d8ac-7406f4aa42f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!mkdir 6-new-12w-0\\n!mv pytorch_model.bin 6-new-12w-0/\\n!mv config.json 6-new-12w-0/\\n!mv special_tokens_map.json 6-new-12w-0/\\n!mv tokenizer_config.json 6-new-12w-0/\\n!mv vocab.txt 6-new-12w-0/'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''!gdown $model_id\n",
    "!gdown 10sF8Ywktd96HqAL0CwvlZZUUGj05CGk5\n",
    "!gdown 16bT7HDv71aRwyh3gBUbKwign1mtyLD2d\n",
    "!gdown 1EE9goZ2JRSD8UTx501q71lGCk-CK3kqG\n",
    "!gdown 1gZZdtAoDnDiLQqjQfGyuwt268Pe5sXW0'''\n",
    "\n",
    "\n",
    "'''!mkdir 6-new-12w-0\n",
    "!mv pytorch_model.bin 6-new-12w-0/\n",
    "!mv config.json 6-new-12w-0/\n",
    "!mv special_tokens_map.json 6-new-12w-0/\n",
    "!mv tokenizer_config.json 6-new-12w-0/\n",
    "!mv vocab.txt 6-new-12w-0/'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig\n",
    "from typing import Optional\n",
    "class ParallelBert(BertForTokenClassification):\n",
    "    def __init__(self):\n",
    "        self.config = AutoConfig.from_pretrained(\"/6-new-12w-0/\")\n",
    "        super().__init__(self.config)\n",
    "        \n",
    "        self.model = nn.DataParallel(BertForTokenClassification.from_pretrained('/6-new-12w-0/'))\n",
    "    def forward(self, inp, attn_mask=Optional[torch.Tensor]):\n",
    "        return self.model(inp, attn_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "phiM-JSYIA22",
    "outputId": "76dc46f2-a962-4cae-a4f2-c1a179e02615"
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('/home/arulybin/6-new-12w-0/')\n",
    "model = BertForTokenClassification.from_pretrained('/home/arulybin/6-new-12w-0/')\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rOnegwj9IA23"
   },
   "source": [
    "# Predict and save raw outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "id": "_1qjq3i-VCEz",
    "outputId": "3d5efb90-6887-4ae4-9ec0-bd235e2cf4f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom transformers_interpret import MultiLabelClassificationExplainer\\nout = []\\nans = []\\nmce = MultiLabelClassificationExplainer(model, tokenizer)\\nfor key in uploaded.keys():\\n    print(key)\\n    out.append(key)\\n    result_dict = {}\\n    for seq_record in SeqIO.parse(StringIO(BytesIO(uploaded[key]).read().decode(\\'UTF-8\\')), \\'fasta\\'):\\n        kmer_seq = seq2kmer(str(seq_record.seq).upper(), 6)\\n        seq_pieces = split_seq(kmer_seq)\\n        #print(seq_record.name)\\n        out.append(seq_record.name)\\n        with torch.no_grad():\\n            preds = []\\n            for seq_piece in seq_pieces:\\n                input_ids = torch.LongTensor(tokenizer.encode(\\' \\'.join(seq_piece), add_special_tokens=False))\\n                print(input_ids.cuda().unsqueeze(0))\\n                break\\n                outputs = torch.softmax(model(input_ids.cuda().unsqueeze(0))[-1],axis = -1)[0,:,1]\\n                preds.append(outputs.cpu().numpy())\\n                print(mce(\\' \\'.join(seq_piece)))\\n        result_dict[seq_record.name] = stitch_np_seq(preds)\\n\\n        labeled, max_label = scipy.ndimage.label(result_dict[seq_record.name]>model_confidence_threshold)\\n        ans.append(np.any(labeled))\\n        #print(\\'  start     end\\')\\n        out.append(\\'  start     end\\')\\n        for label in range(1, max_label+1):\\n            candidate = np.where(labeled == label)[0]\\n            candidate_length = candidate.shape[0]\\n            if candidate_length>minimum_sequence_length:\\n                #print(\\'{:8}\\'.format(candidate[0]), \\'{:8}\\'.format(candidate[-1]))\\n                out.append(\\'{:8}\\'.format(candidate[0]) + \\'{:8}\\'.format(candidate[-1]))\\n\\n    with open(key + \\'.preds.pkl\\',\"wb\") as fh:\\n      pickle.dump(result_dict, fh)\\n    print()\\n\\nwith open(\\'text_predictions.txt\\',\"w\") as fh:\\n    for item in out:\\n        fh.write(\"%s\\n\" % item)\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from transformers_interpret import MultiLabelClassificationExplainer\n",
    "out = []\n",
    "ans = []\n",
    "mce = MultiLabelClassificationExplainer(model, tokenizer)\n",
    "for key in uploaded.keys():\n",
    "    print(key)\n",
    "    out.append(key)\n",
    "    result_dict = {}\n",
    "    for seq_record in SeqIO.parse(StringIO(BytesIO(uploaded[key]).read().decode('UTF-8')), 'fasta'):\n",
    "        kmer_seq = seq2kmer(str(seq_record.seq).upper(), 6)\n",
    "        seq_pieces = split_seq(kmer_seq)\n",
    "        #print(seq_record.name)\n",
    "        out.append(seq_record.name)\n",
    "        with torch.no_grad():\n",
    "            preds = []\n",
    "            for seq_piece in seq_pieces:\n",
    "                input_ids = torch.LongTensor(tokenizer.encode(' '.join(seq_piece), add_special_tokens=False))\n",
    "                print(input_ids.cuda().unsqueeze(0))\n",
    "                break\n",
    "                outputs = torch.softmax(model(input_ids.cuda().unsqueeze(0))[-1],axis = -1)[0,:,1]\n",
    "                preds.append(outputs.cpu().numpy())\n",
    "                print(mce(' '.join(seq_piece)))\n",
    "        result_dict[seq_record.name] = stitch_np_seq(preds)\n",
    "\n",
    "        labeled, max_label = scipy.ndimage.label(result_dict[seq_record.name]>model_confidence_threshold)\n",
    "        ans.append(np.any(labeled))\n",
    "        #print('  start     end')\n",
    "        out.append('  start     end')\n",
    "        for label in range(1, max_label+1):\n",
    "            candidate = np.where(labeled == label)[0]\n",
    "            candidate_length = candidate.shape[0]\n",
    "            if candidate_length>minimum_sequence_length:\n",
    "                #print('{:8}'.format(candidate[0]), '{:8}'.format(candidate[-1]))\n",
    "                out.append('{:8}'.format(candidate[0]) + '{:8}'.format(candidate[-1]))\n",
    "\n",
    "    with open(key + '.preds.pkl',\"wb\") as fh:\n",
    "      pickle.dump(result_dict, fh)\n",
    "    print()\n",
    "\n",
    "with open('text_predictions.txt',\"w\") as fh:\n",
    "    for item in out:\n",
    "        fh.write(\"%s\\n\" % item)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Q2SfbSxAE6sZ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from joblib import load\n",
    "from tqdm import trange\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.utils import data\n",
    "\n",
    "ZDNA = load(\"/home/arulybin/ZDNA_cousine.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "QZHcksM3zwjq"
   },
   "outputs": [],
   "source": [
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, chroms,\n",
    "                 dna_source,\n",
    "                 labels_source, intervals, lrp_feat=[]):\n",
    "        self.chroms = chroms\n",
    "        #self.features = features\n",
    "        self.dna_source = dna_source\n",
    "        #self.features_source = features_source\n",
    "        self.labels_source = labels_source\n",
    "        self.intervals = intervals\n",
    "        self.le = LabelBinarizer().fit(np.array([[\"A\"], [\"C\"], [\"T\"], [\"G\"]]))\n",
    "        self.lrp_feat = lrp_feat\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.intervals)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        interval = self.intervals[index]\n",
    "        chrom = interval[0]\n",
    "        begin = int(interval[1])\n",
    "        end = int(interval[2])\n",
    "        dna_OHE = self.le.transform(list(self.dna_source[chrom][begin:end].upper()))\n",
    "        \n",
    "        dna_letters = list(self.dna_source[chrom][begin:end + 5].upper())\n",
    "\n",
    "        #X = dna_OHE.astype(np.float32)\n",
    "        X = \"\".join(dna_letters)\n",
    "        y = self.labels_source[interval[0]][interval[1]: interval[2]]\n",
    "        if len(self.lrp_feat) > 0:\n",
    "            X = X[:,np.sort(self.lrp_feat)]\n",
    "\n",
    "        return (X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 640
    },
    "id": "J-QpZrTW0FuT",
    "outputId": "b1f35729-41b2-4257-9f9c-0cfb87c25038"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2489564/2489564 [00:34<00:00, 72681.40it/s]\n",
      "100%|██████████| 2421935/2421935 [00:32<00:00, 74253.51it/s]\n",
      "100%|██████████| 1982955/1982955 [00:26<00:00, 75236.28it/s]\n",
      "100%|██████████| 1902145/1902145 [00:25<00:00, 75974.82it/s]\n",
      "100%|██████████| 1815382/1815382 [00:23<00:00, 75641.65it/s]\n",
      "100%|██████████| 1708059/1708059 [00:23<00:00, 73702.39it/s]\n",
      "100%|██████████| 1593459/1593459 [00:20<00:00, 78133.87it/s]\n",
      "100%|██████████| 1451386/1451386 [00:20<00:00, 70240.04it/s]\n",
      "100%|██████████| 1383947/1383947 [00:17<00:00, 79610.24it/s]\n",
      "100%|██████████| 1337974/1337974 [00:17<00:00, 78193.62it/s]\n",
      "100%|██████████| 1350866/1350866 [00:19<00:00, 70167.16it/s]\n",
      "100%|██████████| 1332753/1332753 [00:16<00:00, 79237.60it/s]\n",
      "100%|██████████| 1143643/1143643 [00:14<00:00, 78210.36it/s]\n",
      "100%|██████████| 1070437/1070437 [00:13<00:00, 80370.16it/s]\n",
      "100%|██████████| 1019911/1019911 [00:16<00:00, 62514.64it/s]\n",
      "100%|██████████| 903383/903383 [00:11<00:00, 76534.17it/s]\n",
      "100%|██████████| 832574/832574 [00:10<00:00, 81008.36it/s]\n",
      "100%|██████████| 803732/803732 [00:10<00:00, 80039.90it/s]\n",
      "100%|██████████| 586176/586176 [00:07<00:00, 78709.16it/s]\n",
      "100%|██████████| 644441/644441 [00:08<00:00, 77101.11it/s]\n",
      "100%|██████████| 467099/467099 [00:05<00:00, 78271.05it/s]\n",
      "100%|██████████| 508184/508184 [00:06<00:00, 80042.53it/s]\n",
      "100%|██████████| 1560408/1560408 [00:24<00:00, 62782.23it/s]\n",
      "100%|██████████| 572274/572274 [00:07<00:00, 77087.39it/s]\n",
      "100%|██████████| 165/165 [00:00<00:00, 10808.71it/s]\n"
     ]
    }
   ],
   "source": [
    "width = 100\n",
    "\n",
    "np.random.seed(10)\n",
    "\n",
    "ints_in = []\n",
    "ints_out = []\n",
    "chrom_names = [f'chr{i}' for i in list(range(1, 23)) + ['X', 'Y','M']]\n",
    "\n",
    "for chrm in chrom_names:\n",
    "    for st in trange(0, ZDNA[chrm].shape - width, width):\n",
    "        interval = [st, min(st + width, ZDNA[chrm].shape)]\n",
    "        if ZDNA[chrm][interval[0]: interval[1]].any():\n",
    "            ints_in.append([chrm, interval[0], interval[1]])\n",
    "        else:\n",
    "            ints_out.append([chrm, interval[0], interval[1]])\n",
    "\n",
    "ints_in = np.array(ints_in)\n",
    "ints_out = np.array(ints_out)[np.random.choice(range(len(ints_out)), size=len(ints_in) * 3, replace=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "izTomSPi4vX6"
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "equalized = np.vstack((ints_in, ints_out))\n",
    "equalized = [[inter[0], int(inter[1]), int(inter[2])] for inter in equalized]\n",
    "\n",
    "train_inds, test_inds = next(StratifiedKFold().split(equalized, [f\"{int(i < 400)}_{elem[0]}\"\n",
    "                                                                 for i, elem\n",
    "                                                                 in enumerate(equalized)]))\n",
    "\n",
    "train_intervals, test_intervals = [equalized[i] for i in train_inds], [equalized[i] for i in test_inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ddda33e14794327b9d6e035fa5db87d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def chrom_reader(chrom):\n",
    "    files = sorted([i for i in os.listdir(f'/home/arulybin/z_dna/hg38_dna/') if f\"{chrom}_\" in i])\n",
    "    return ''.join([load(f\"z_dna/hg38_dna/{file}\") for file in files])\n",
    "DNA = {chrom:chrom_reader(chrom) for chrom in tqdm(chrom_names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36161"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "params = {'batch_size':1,\n",
    "          'num_workers':4,\n",
    "          'shuffle':True}\n",
    "\n",
    "\n",
    "train_dataset = Dataset(chrom_names, \n",
    "                       DNA, \n",
    "                       ZDNA, train_intervals, lrp_feat = [])\n",
    "\n",
    "test_dataset = Dataset(chrom_names, \n",
    "                       DNA, \n",
    "                       ZDNA, test_intervals, lrp_feat = [])\n",
    "\n",
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обработано 4340 последовательностей за 14265.589334964752 секунд\n"
     ]
    }
   ],
   "source": [
    "from transformers_interpret import TokenClassificationExplainer\n",
    "from IPython.display import clear_output\n",
    "from time import time\n",
    "\n",
    "mce = TokenClassificationExplainer(model, tokenizer)\n",
    "\n",
    "TP, FP, TN, FN = 0, 0, 0, 0\n",
    "num_seqs = 100000\n",
    "\n",
    "res_dict = {}\n",
    "counter = {}\n",
    "ts = time()\n",
    "for i in range(len(test_dataset)):\n",
    "    sequence, labels = test_dataset[i]\n",
    "    seq_piece = seq2kmer(sequence, 6) \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        input_ids = torch.LongTensor(tokenizer.encode(seq_piece, add_special_tokens=False))\n",
    "        outputs = (torch.softmax(model(input_ids.cuda().unsqueeze(0))[-1],axis = -1)[0,:,1] > model_confidence_threshold).to(torch.int32).cpu()\n",
    "        \n",
    "        tp_res = ((outputs == 1) & (labels == 1))\n",
    "        tp_vals = {}\n",
    "        for res_i, res in enumerate(tp_res):\n",
    "            if res:\n",
    "                tp_vals[seq_piece[res_i]] = 1\n",
    "                \n",
    "        interpret_res = mce(\" \".join(seq_piece), ignored_labels=[\"LABEL_0\"])\n",
    "        for k in interpret_res.keys():\n",
    "            if k in tp_vals:\n",
    "                for interpr_pair in interpret_res[k][\"attribution_scores\"]:\n",
    "                    res_dict[interpr_pair[0]] = res_dict.get(interpr_pair[0], 0) + interpr_pair[1]\n",
    "                    counter[interpr_pair[0]] = counter.get(interpr_pair[0], 0) + 1\n",
    "        \n",
    "        TP += ((outputs == 1) & (labels == 1)).sum().item()\n",
    "        FP += ((outputs == 1) & (labels == 0)).sum().item()\n",
    "        TN += ((outputs == 0) & (labels == 0)).sum().item()\n",
    "        FN += ((outputs == 0) & (labels == 1)).sum().item()\n",
    "    \n",
    "        if (i + 1) % 1 == 0:\n",
    "            clear_output(wait=True)\n",
    "            print(f\"Обработано {i + 1} последовательностей за {time() - ts} секунд\")\n",
    "        num_seqs -= 1\n",
    "        if num_seqs <= 0:\n",
    "            break\n",
    "\n",
    "precision = TP/(TP + FP)\n",
    "recall = TP/(TP + FN)\n",
    "F1_score = 2*precision*recall/(precision + recall)\n",
    "\n",
    "for key in res_dict:\n",
    "    res_dict[key] /= counter[key]\n",
    "\n",
    "print(f\"precision: {precision}, recall: {recall}, F_score: {F1_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import shap\n",
    "from time import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def f(x):\n",
    "    out_tensors = []\n",
    "    with torch.no_grad():\n",
    "        for seq in x:\n",
    "            input_ids = torch.LongTensor(tokenizer.encode(seq, add_special_tokens=False)).cuda()\n",
    "            outputs = torch.softmax(model(input_ids.cuda().unsqueeze(0))[-1],axis = -1)[:, :, -1].cuda()\n",
    "            out_tensors.append(outputs)\n",
    "    out = torch.cat(out_tensors, dim=0)\n",
    "    return out\n",
    "\n",
    "TP, FP, TN, FN = 0, 0, 0, 0\n",
    "num_seqs = 15000\n",
    "\n",
    "spec_tokens = [\"[CLS]\", \"[SEP]\"]\n",
    "res_dict = {}\n",
    "counter = {}\n",
    "ts = time()\n",
    "explainer = shap.Explainer(f, tokenizer)\n",
    "\n",
    "for i in range(len(test_dataset)):\n",
    "    sequence, labels = test_dataset[i]\n",
    "    seq_piece = seq2kmer(sequence, 6) \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        input_ids = torch.LongTensor(tokenizer.encode(seq_piece, add_special_tokens=False))\n",
    "        outputs = (torch.softmax(model(input_ids.cuda().unsqueeze(0))[-1],axis = -1)[0,:,1] > model_confidence_threshold).to(torch.int32).cpu()\n",
    "        shap_values = explainer([\" \".join(seq_piece)])\n",
    "        tp_res = ((outputs == 1) & (labels == 1))\n",
    "        \n",
    "        tp_shap_values_sum = shap_values.values.squeeze(0)[:, tp_res].sum(axis = 1)\n",
    "        data_tokens = shap_values.data[0]\n",
    "        spec_counter = 0\n",
    "        for j, el in enumerate(data_tokens):\n",
    "            if len(el) > 0 and el[0] == \" \":\n",
    "                data_tokens[j] = el[1:]\n",
    "            elif len(el) == 0:\n",
    "                data_tokens[j] = spec_tokens[spec_counter]\n",
    "                spec_counter += 1\n",
    "        \n",
    "        for j, seq in enumerate(data_tokens):\n",
    "            res_dict[seq] = res_dict.get(seq, 0) + tp_shap_values_sum[j]\n",
    "            counter[seq] = counter.get(seq, 0) + tp_res.sum().item()\n",
    "        \n",
    "        TP += ((outputs == 1) & (labels == 1)).sum().item()\n",
    "        FP += ((outputs == 1) & (labels == 0)).sum().item()\n",
    "        TN += ((outputs == 0) & (labels == 0)).sum().item()\n",
    "        FN += ((outputs == 0) & (labels == 1)).sum().item()\n",
    "    \n",
    "        if (i + 1) % 1 == 0:\n",
    "            clear_output(wait=True)\n",
    "            print(f\"Обработано {i + 1} последовательностей за {time() - ts} секунд\")\n",
    "            \n",
    "        num_seqs -= 1\n",
    "        if num_seqs <= 0:\n",
    "            break\n",
    "\n",
    "precision = TP/(TP + FP)\n",
    "recall = TP/(TP + FN)\n",
    "F1_score = 2*precision*recall/(precision + recall)\n",
    "\n",
    "for key in res_dict:\n",
    "    res_dict[key] /= counter[key]\n",
    "\n",
    "print(f\"precision: {precision}, recall: {recall}, F_score: {F1_score}\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_interpret_res = pd.DataFrame.from_dict(res_dict, orient=\"index\").rename(columns={0: \"impact\"})\n",
    "df_interpret_res_sorted = df_interpret_res.sort_values(by=[\"impact\"], ascending=False)\n",
    "df_interpret_res_sorted.to_csv(\"integrated_gradients_interpret_res.csv\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7075755,
     "sourceId": 11312858,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "zdna_env2",
   "language": "python",
   "name": "zdna_env2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
